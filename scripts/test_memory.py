#!/usr/bin/env python
"""
Memory Test Script

Checks if your system can handle the AmEx 50GB dataset.
Provides recommendations for chunk size and configuration.
"""

import psutil
import sys
from pathlib import Path

# Add src to path
sys.path.append(str(Path(__file__).parent.parent))


def bytes_to_gb(bytes_val):
    """Convert bytes to GB."""
    return bytes_val / (1024 ** 3)


def check_system_memory():
    """Check system memory and provide recommendations."""
    print("=" * 70)
    print("AMEX DATASET MEMORY CHECK")
    print("=" * 70)

    # Get system memory
    mem = psutil.virtual_memory()
    total_ram = bytes_to_gb(mem.total)
    available_ram = bytes_to_gb(mem.available)
    used_ram = bytes_to_gb(mem.used)

    print(f"\nðŸ“Š System Memory:")
    print(f"  Total RAM: {total_ram:.1f} GB")
    print(f"  Used RAM: {used_ram:.1f} GB")
    print(f"  Available RAM: {available_ram:.1f} GB")
    print(f"  Usage: {mem.percent:.1f}%")

    # Check swap
    swap = psutil.swap_memory()
    if swap.total > 0:
        swap_gb = bytes_to_gb(swap.total)
        print(f"  Swap Space: {swap_gb:.1f} GB")
    else:
        print(f"  Swap Space: None (consider adding swap)")

    # Check disk space
    disk = psutil.disk_usage('.')
    free_disk = bytes_to_gb(disk.free)
    print(f"\nðŸ’¾ Disk Space:")
    print(f"  Free Disk: {free_disk:.1f} GB")

    # Provide recommendations
    print(f"\nðŸŽ¯ Recommendations:")

    # RAM check
    if total_ram < 16:
        print("  âŒ RAM Status: INSUFFICIENT")
        print("  âš ï¸  Minimum 32GB RAM required for full pipeline")
        print("  ðŸ’¡ Consider: Cloud instance or smaller chunk size")
        chunk_size = 100_000
        can_train = False
    elif total_ram < 32:
        print("  âš ï¸  RAM Status: MARGINAL")
        print("  ðŸ’¡ Should work with optimizations")
        print("  ðŸ’¡ Close all other applications")
        chunk_size = 250_000
        can_train = True
    elif total_ram < 64:
        print("  âœ… RAM Status: GOOD")
        print("  ðŸ’¡ Recommended for full pipeline")
        chunk_size = 500_000
        can_train = True
    else:
        print("  âœ… RAM Status: EXCELLENT")
        print("  ðŸ’¡ Can handle all models efficiently")
        chunk_size = 1_000_000
        can_train = True

    # Disk check
    if free_disk < 100:
        print("  âŒ Disk Status: INSUFFICIENT")
        print("  âš ï¸  Need at least 100GB free space")
        print("  ðŸ’¡ Clean up disk or use external drive")
        can_train = False
    elif free_disk < 200:
        print("  âš ï¸  Disk Status: MARGINAL")
        print("  ðŸ’¡ Monitor disk usage during training")
    else:
        print("  âœ… Disk Status: GOOD")

    # GPU check
    try:
        import torch
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            print(f"\nðŸŽ® GPU:")
            for i in range(gpu_count):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_mem = torch.cuda.get_device_properties(i).total_memory
                gpu_mem_gb = bytes_to_gb(gpu_mem)
                print(f"  âœ… GPU {i}: {gpu_name} ({gpu_mem_gb:.1f} GB)")

            if gpu_mem_gb < 8:
                print("  ðŸ’¡ GPU memory < 8GB: Use smaller batch sizes")
        else:
            print(f"\nðŸŽ® GPU: None detected (CPU training only)")
    except ImportError:
        print(f"\nðŸŽ® GPU: PyTorch not installed")

    # Configuration recommendations
    print(f"\nâš™ï¸  Recommended Configuration:")
    print(f"  chunk_size: {chunk_size:,}")

    if total_ram < 32:
        print(f"  batch_size: 128")
        print(f"  num_workers: 2")
        print(f"  models: lightgbm only (fastest)")
    elif total_ram < 64:
        print(f"  batch_size: 256")
        print(f"  num_workers: 4")
        print(f"  models: lightgbm, xgboost, catboost")
    else:
        print(f"  batch_size: 512")
        print(f"  num_workers: 8")
        print(f"  models: all models")

    # Estimated memory usage
    print(f"\nðŸ“ˆ Estimated Memory Usage:")

    if chunk_size == 100_000:
        peak_usage = 8
    elif chunk_size == 250_000:
        peak_usage = 12
    elif chunk_size == 500_000:
        peak_usage = 18
    else:
        peak_usage = 24

    print(f"  Peak RAM during training: ~{peak_usage} GB")
    print(f"  Buffer available: {available_ram - peak_usage:.1f} GB")

    if available_ram < peak_usage:
        print(f"  âš ï¸  WARNING: May need to close other apps")

    # Final verdict
    print(f"\n" + "=" * 70)
    if can_train:
        print("âœ… STATUS: READY FOR TRAINING")
        print("\nNext steps:")
        print("  1. Update configs/config.yaml with recommended settings")
        print("  2. Run: python train.py --config configs/config.yaml")
    else:
        print("âŒ STATUS: NOT READY")
        print("\nOptions:")
        print("  1. Upgrade RAM to 32GB+")
        print("  2. Use cloud instance (AWS, GCP, Kaggle)")
        print("  3. Free up disk space")

    print("=" * 70)

    return can_train


def test_chunk_loading():
    """Test loading a small chunk to verify setup."""
    print("\nðŸ§ª Testing chunk loading...")

    try:
        import pandas as pd
        import numpy as np
        from pathlib import Path

        # Check if data exists
        data_file = Path('./input/train_data.csv')

        if not data_file.exists():
            print("  âš ï¸  Data file not found: ./input/train_data.csv")
            print("  ðŸ’¡ Download data and place in ./input/ directory")
            return False

        # Try loading a small chunk
        print("  Loading 10,000 rows as test...")
        chunk = pd.read_csv(data_file, nrows=10_000)

        print(f"  âœ… Successfully loaded {len(chunk):,} rows")
        print(f"  âœ… Columns: {len(chunk.columns)}")
        print(f"  âœ… Memory: {chunk.memory_usage().sum() / 1024**2:.2f} MB")

        # Test memory optimization
        from src.preprocessing import reduce_mem_usage

        print("  Testing memory optimization...")
        chunk_opt = reduce_mem_usage(chunk, verbose=False)

        original_mb = chunk.memory_usage().sum() / 1024**2
        optimized_mb = chunk_opt.memory_usage().sum() / 1024**2
        reduction = 100 * (1 - optimized_mb / original_mb)

        print(f"  âœ… Memory reduced: {original_mb:.2f} MB â†’ {optimized_mb:.2f} MB")
        print(f"  âœ… Reduction: {reduction:.1f}%")

        return True

    except Exception as e:
        print(f"  âŒ Error: {str(e)}")
        return False


if __name__ == "__main__":
    # Check system
    can_train = check_system_memory()

    # Test loading (if data available)
    if can_train:
        print("\n")
        test_chunk_loading()

    # Exit code
    sys.exit(0 if can_train else 1)
